import json
import requests
from llama_cpp import Llama

from bulker import *

model_path = "./bin/codellama-13b-python.Q5_K_M.gguf"
# To download manually from here and put in a bin folder
# https://huggingface.co/TheBloke/CodeLlama-13B-Python-GGUF/blob/main/codellama-13b-python.Q5_K_M.gguf
    

def create_cvss_llama2(cve_path, cve_year, cve_id):
    
    LLM = Llama(model_path=model_path, max_tokens=4096, n_ctx=4096, gpu_layers=50, verbose=True)
    print("Loaded Llama 2 model")

    cve = get_cve(cve_path, cve_year, cve_id)
    data = str(cve)

    prompt = "We are a society that creates cvss for cve.\
    We need to get a objective score (the cvss) based on the informations that are on the cve.\
    Here is one cve : " + data + "\
    Create a score for it and explain the number."

    print(prompt)

    output = LLM(prompt)
    print(output["choices"][0]["text"])