import os
import json
from langchain_community.llms import CTransformers

from bulker import *

os.environ['XDG_CACHE_HOME'] = './model/cache'
config = {
    'temperature':0.00,
    'context_length':4000
}

def create_cvss_mistral(instruct, cve_path, cve_year, cve_id):
    if instruct:
        model_ia = 'TheBloke/Mistral-7B-instruct-v0.2-GGUF'
    else:
        model_ia = 'TheBloke/Mistral-7B-codealpaca-lora-GGUF'

    # This will install the model on the computer if not present and the load it
    llm = CTransformers(
        model=model_ia,
        model_type='mistral',
        config=config
    )

    print("Loaded Ollama Mistral model")

    cve = get_cve(cve_path, cve_year, cve_id)
    data = str(cve)

    prompt = "We are a society that creates cvss for cve.\
    We need to get a objective score (the cvss) based on the informations that are on the cve.\
    Here is one cve : " + data + "\
    Create a score for it and explain the number."

    print(prompt)

    answer = llm.invoke(prompt)
    print(answer)